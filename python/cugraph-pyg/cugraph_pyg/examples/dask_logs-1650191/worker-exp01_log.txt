RUNNING: "python -m dask_cuda.cli.dask_cuda_worker --rmm-pool-size=14G
             --local-directory=/tmp/
             --scheduler-file=/root/cugraph/python/cugraph-pyg/cugraph_pyg/examples/scheduler.json
             --memory-limit=auto
             --device-memory-limit=auto
            "
2023-04-05 13:41:06,010 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:35409'
2023-04-05 13:41:06,012 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.104.11:37947'
2023-04-05 13:41:07,152 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-05 13:41:07,152 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-05 13:41:07,154 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-05 13:41:07,154 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-05 13:41:07,415 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-04-05 13:41:07,420 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2023-04-05 13:41:08,709 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:33907
2023-04-05 13:41:08,709 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:33907
2023-04-05 13:41:08,709 - distributed.worker - INFO -          dashboard at:        10.120.104.11:39715
2023-04-05 13:41:08,709 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-04-05 13:41:08,709 - distributed.worker - INFO - -------------------------------------------------
2023-04-05 13:41:08,709 - distributed.worker - INFO -               Threads:                          1
2023-04-05 13:41:08,709 - distributed.worker - INFO -                Memory:                 755.28 GiB
2023-04-05 13:41:08,709 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-e_btqy3j
2023-04-05 13:41:08,710 - distributed.worker - INFO - Starting Worker plugin RMMSetup-36351bd7-9ad9-4a87-add8-681e7e2b6454
2023-04-05 13:41:08,732 - distributed.worker - INFO -       Start worker at:  tcp://10.120.104.11:44805
2023-04-05 13:41:08,732 - distributed.worker - INFO -          Listening to:  tcp://10.120.104.11:44805
2023-04-05 13:41:08,732 - distributed.worker - INFO -          dashboard at:        10.120.104.11:40429
2023-04-05 13:41:08,732 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.104.11:8786
2023-04-05 13:41:08,732 - distributed.worker - INFO - -------------------------------------------------
2023-04-05 13:41:08,732 - distributed.worker - INFO -               Threads:                          1
2023-04-05 13:41:08,732 - distributed.worker - INFO -                Memory:                 755.28 GiB
2023-04-05 13:41:08,732 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ytgc1swo
2023-04-05 13:41:08,733 - distributed.worker - INFO - Starting Worker plugin RMMSetup-dd185595-6d75-451f-b98d-76108b34295b
2023-04-05 13:41:08,842 - distributed.worker - INFO - Starting Worker plugin PreImport-ab9f4d09-a562-46b4-9415-0a3bbac07f99
2023-04-05 13:41:08,842 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c25a9e3c-7970-4ffd-8dc4-0c2b1d6b607d
2023-04-05 13:41:08,846 - distributed.worker - INFO - -------------------------------------------------
2023-04-05 13:41:08,857 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fb3d09ec-4b4f-45ef-bcbd-0afbff16475e
2023-04-05 13:41:08,857 - distributed.worker - INFO - Starting Worker plugin PreImport-39452ed4-c80c-4b0f-add7-318a34a9699c
2023-04-05 13:41:08,858 - distributed.worker - INFO - -------------------------------------------------
2023-04-05 13:41:08,861 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-04-05 13:41:08,861 - distributed.worker - INFO - -------------------------------------------------
2023-04-05 13:41:08,863 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-04-05 13:41:08,868 - distributed.worker - INFO -         Registered to:   tcp://10.120.104.11:8786
2023-04-05 13:41:08,868 - distributed.worker - INFO - -------------------------------------------------
2023-04-05 13:41:08,870 - distributed.core - INFO - Starting established connection to tcp://10.120.104.11:8786
2023-04-05 13:50:46,218 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.120.104.11:35409'. Reason: nanny-close
2023-04-05 13:50:46,219 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-04-05 13:50:46,219 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:44805. Reason: worker-handle-scheduler-connection-broken
2023-04-05 13:50:46,219 - distributed.worker - INFO - Stopping worker at tcp://10.120.104.11:33907. Reason: worker-handle-scheduler-connection-broken
2023-04-05 13:50:46,219 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.120.104.11:37947'. Reason: nanny-close
2023-04-05 13:50:46,220 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2023-04-05 13:50:49,421 - distributed.nanny - WARNING - Worker process still alive after 3.1999960327148442 seconds, killing
2023-04-05 13:50:49,422 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing
2023-04-05 13:50:49,578 - distributed.nanny - INFO - Worker process 1650360 was killed by signal 9
2023-04-05 13:50:49,641 - distributed.nanny - INFO - Worker process 1650363 was killed by signal 9
