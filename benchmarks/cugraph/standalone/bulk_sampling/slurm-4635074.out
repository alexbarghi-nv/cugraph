Node IP: 10.248.0.202
Num Nodes: 1
Num GPUs Per Node: 8
no change     /opt/conda/condabin/conda
no change     /opt/conda/bin/conda
no change     /opt/conda/bin/conda-env
no change     /opt/conda/bin/activate
no change     /opt/conda/bin/deactivate
no change     /opt/conda/etc/profile.d/conda.sh
no change     /opt/conda/etc/fish/conf.d/conda.fish
no change     /opt/conda/shell/condabin/Conda.psm1
no change     /opt/conda/shell/condabin/conda-hook.ps1
no change     /opt/conda/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /opt/conda/etc/profile.d/conda.csh
no change     /root/.bashrc
No action taken.

EnvironmentNameNotFound: Could not find conda environment: rapids
You can list all discoverable environments with `conda info --envs`.


properly waiting for workers to connect
>>>> Using cluster configurtion for TCP
>>>> Logs written to: /logs
wait_for_workers.py - initializing client...done.
wait_for_workers.py expected 8 but got 0, waiting...
scheduler started.
worker(s) started.
waiting for worker pid 1599875 to finish before exiting script...
wait_for_workers.py expected 8 but got 0, waiting...
wait_for_workers.py got 8 workers, done.
0
Launching Python Script
INFO:__main__:starting dask client
INFO:__main__:dask client started
INFO:__main__:dataset: ogbn_papers100M
INFO:__main__:batch size: 512
INFO:__main__:fanout: [10, 10, 10]
INFO:__main__:seeds_per_call: 524288
INFO:__main__:num epochs: 1
INFO:__main__:ogbn_papers100M
INFO:__main__:Number of input edges = 1,615,685,872
INFO:__main__:constructed graph
/opt/conda/lib/python3.10/site-packages/cudf/core/index.py:3329: FutureWarning: cudf.StringIndex is deprecated and will be removed from cudf in a future version. Use cudf.Index with the appropriate dtype instead.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/cudf/core/index.py:3329: FutureWarning: cudf.StringIndex is deprecated and will be removed from cudf in a future version. Use cudf.Index with the appropriate dtype instead.
  warnings.warn(
INFO:__main__:input memory: 38776460928
/scripts/cugraph_bulk_sampling.py:840: UserWarning: An Exception Occurred!
  warnings.warn("An Exception Occurred!")
Traceback (most recent call last):
  File "/scripts/cugraph_bulk_sampling.py", line 812, in <module>
    ) = benchmark_cugraph_bulk_sampling(
  File "/scripts/cugraph_bulk_sampling.py", line 566, in benchmark_cugraph_bulk_sampling
    os.makedirs(output_subdir)
  File "/opt/conda/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: '/samples/ogbn_papers100M[1]_b512_f[10, 10, 10]'

Dask client created using /scripts/mg_utils/dask_scheduler.json
Loading edge index for edge type paper__cites__paper
Loading node labels for node type paper (offset=0)
[Errno 17] File exists: '/samples/ogbn_papers100M[1]_b512_f[10, 10, 10]'
----------------------------------------dataset = ogbn_papers100M completed----------------------------------------

Dask client closed.
[1705709529.910896] [luna-0069:1600010:0]          parser.c:2036 UCX  WARN  unused environment variable: UCX_MEMTYPE_CACHE (maybe: UCX_MEMTYPE_CACHE?)
[1705709529.910896] [luna-0069:1600010:0]          parser.c:2036 UCX  WARN  (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
1599819 /bin/bash /scripts/mg_utils/run-dask-process.sh scheduler workers
1599863 /opt/conda/bin/python3.10 /opt/conda/bin/dask-scheduler --protocol=tcp --scheduler-file /scripts/mg_utils/dask_scheduler.json
1599875 /opt/conda/bin/python /opt/conda/bin/dask-cuda-worker --rmm-pool-size=28G --rmm-async --local-directory=/tmp/abarghi --scheduler-file=/scripts/mg_utils/dask_scheduler.json --memory-limit=auto --device-memory-limit=auto
10991 /home/selene-nfs/etc/dcgm-collector/venv/bin/python -m hwinf_dcgm_collector.hwinf_dcgm_collector
1599879 /opt/conda/bin/python -c from multiprocessing.resource_tracker import main;main(46)
1599882 /opt/conda/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=47, pipe_handle=53) --multiprocessing-fork
1599886 /opt/conda/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=47, pipe_handle=60) --multiprocessing-fork
1599890 /opt/conda/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=47, pipe_handle=71) --multiprocessing-fork
1599895 /opt/conda/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=47, pipe_handle=76) --multiprocessing-fork
1599898 /opt/conda/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=47, pipe_handle=83) --multiprocessing-fork
1599903 /opt/conda/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=47, pipe_handle=92) --multiprocessing-fork
1599906 /opt/conda/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=47, pipe_handle=97) --multiprocessing-fork
1599910 /opt/conda/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=47, pipe_handle=102) --multiprocessing-fork
pkill: killing pid 10991 failed: Operation not permitted
10991 /home/selene-nfs/etc/dcgm-collector/venv/bin/python -m hwinf_dcgm_collector.hwinf_dcgm_collector
1599879 /opt/conda/bin/python -c from multiprocessing.resource_tracker import main;main(46)
1599882 python
1599886 python
1599890 python
1599895 python
1599898 python
1599903 python
1599906 python
1599910 python
1599863 /opt/conda/bin/python3.10 /opt/conda/bin/dask-scheduler --protocol=tcp --scheduler-file /scripts/mg_utils/dask_scheduler.json
1599875 /opt/conda/bin/python /opt/conda/bin/dask-cuda-worker --rmm-pool-size=28G --rmm-async --local-directory=/tmp/abarghi --scheduler-file=/scripts/mg_utils/dask_scheduler.json --memory-limit=auto --device-memory-limit=auto
srun: Job 4635074 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Step created for job 4635074
[2024-01-19 16:13:37,716] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-01-19 16:13:37,716] torch.distributed.run: [WARNING] 
[2024-01-19 16:13:37,716] torch.distributed.run: [WARNING] *****************************************
[2024-01-19 16:13:37,716] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-01-19 16:13:37,716] torch.distributed.run: [WARNING] *****************************************
worker initialized
worker initialized
worker initialized
worker initialized
worker initialized
worker initialized
worker initialized
worker initialized
INFO:OGBNPapers100MDataset:Processing dataset...
INFO:OGBNPapers100MDataset:Processing node features...
INFO:OGBNPapers100MDataset:Processing edge index...
INFO:OGBNPapers100MDataset:Processing labels...
done creating model
done creating model
done creating model
done creating model
done creating model
done creating model
INFO:bench_cugraph_training:Trainer ready on rank 5
done creating model
INFO:bench_cugraph_training:Trainer ready on rank 1
INFO:bench_cugraph_training:Trainer ready on rank 2
INFO:bench_cugraph_training:Trainer ready on rank 0
done creating model
INFO:bench_cugraph_training:Trainer ready on rank 7
INFO:bench_cugraph_training:Trainer ready on rank 6
INFO:bench_cugraph_training:Trainer ready on rank 3
INFO:bench_cugraph_training:Trainer ready on rank 4
Creating dataloaderCreating dataloader

Creating dataloader
Creating dataloader
Time to create dataloader = 0.00 secondsTime to create dataloader = 0.00 seconds

Time to create dataloader = 0.00 seconds
INFO:DGLCuGraphTrainer:getting data
INFO:DGLCuGraphTrainer:getting data
INFO:DGLCuGraphTrainer:getting data
Time to create dataloader = 0.00 seconds
/opt/conda/lib/python3.10/site-packages/cugraph/gnn/feature_storage/feat_storage.py:230: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/torch/csrc/utils/tensor_numpy.cpp:206.)
  ar = torch.from_numpy(ar)
/opt/conda/lib/python3.10/site-packages/cugraph/gnn/feature_storage/feat_storage.py:230: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/torch/csrc/utils/tensor_numpy.cpp:206.)
  ar = torch.from_numpy(ar)
INFO:DGLCuGraphTrainer:getting data
/opt/conda/lib/python3.10/site-packages/cugraph/gnn/feature_storage/feat_storage.py:230: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/torch/csrc/utils/tensor_numpy.cpp:206.)
  ar = torch.from_numpy(ar)
Creating dataloader
/opt/conda/lib/python3.10/site-packages/cugraph/gnn/feature_storage/feat_storage.py:230: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/torch/csrc/utils/tensor_numpy.cpp:206.)
  ar = torch.from_numpy(ar)
Time to create dataloader = 0.00 seconds
Creating dataloader
INFO:DGLCuGraphTrainer:getting data
Time to create dataloader = 0.00 seconds
/opt/conda/lib/python3.10/site-packages/cugraph/gnn/feature_storage/feat_storage.py:230: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/torch/csrc/utils/tensor_numpy.cpp:206.)
  ar = torch.from_numpy(ar)
INFO:DGLCuGraphTrainer:getting data
Creating dataloader
/opt/conda/lib/python3.10/site-packages/cugraph/gnn/feature_storage/feat_storage.py:230: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/torch/csrc/utils/tensor_numpy.cpp:206.)
  ar = torch.from_numpy(ar)
Time to create dataloader = 0.00 seconds
INFO:DGLCuGraphTrainer:getting data
/opt/conda/lib/python3.10/site-packages/cugraph/gnn/feature_storage/feat_storage.py:230: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/torch/csrc/utils/tensor_numpy.cpp:206.)
  ar = torch.from_numpy(ar)
Creating dataloader
Time to create dataloader = 0.00 seconds
INFO:DGLCuGraphTrainer:getting data
/opt/conda/lib/python3.10/site-packages/cugraph/gnn/feature_storage/feat_storage.py:230: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/torch/csrc/utils/tensor_numpy.cpp:206.)
  ar = torch.from_numpy(ar)
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 227, in __getattr__
    return self[key]
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1314, in __getitem__
    return self._get_columns_by_label(arg, downcast=True)
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1973, in _get_columns_by_label
    ca = self._data.select_by_label(labels)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 397, in select_by_label
    return self._select_by_label_grouped(key)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 552, in _select_by_label_grouped
    result = self._grouped_data[key]
KeyError: 'major_offsets'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scripts/bench_cugraph_training.py", line 271, in <module>
    main(args)
  File "/scripts/bench_cugraph_training.py", line 262, in main
    stats = trainer.train()
  File "/scripts/trainers/dgl/trainers_dgl.py", line 211, in train
    num_batches, total_loss = train_epoch(
  File "/scripts/trainers/dgl/trainers_dgl.py", line 90, in train_epoch
    for iter_i, (input_nodes, output_nodes, blocks) in enumerate(loader):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 53, in fetch
    data = self.dataset[possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/dataset.py", line 69, in __getitem__
    create_homogeneous_sampled_graphs_from_dataframe_csc(df)
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 556, in create_homogeneous_sampled_graphs_from_dataframe_csc
    *(_process_sampled_df_csc(sampled_df))
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 446, in _process_sampled_df_csc
    major_offsets = cast_to_tensor(df.major_offsets.dropna())
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 229, in __getattr__
    raise AttributeError(
AttributeError: DataFrame object has no attribute major_offsets
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 227, in __getattr__
    return self[key]
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1314, in __getitem__
    return self._get_columns_by_label(arg, downcast=True)
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1973, in _get_columns_by_label
    ca = self._data.select_by_label(labels)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 397, in select_by_label
    return self._select_by_label_grouped(key)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 552, in _select_by_label_grouped
    result = self._grouped_data[key]
KeyError: 'major_offsets'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scripts/bench_cugraph_training.py", line 271, in <module>
    main(args)
  File "/scripts/bench_cugraph_training.py", line 262, in main
    stats = trainer.train()
  File "/scripts/trainers/dgl/trainers_dgl.py", line 211, in train
    num_batches, total_loss = train_epoch(
  File "/scripts/trainers/dgl/trainers_dgl.py", line 90, in train_epoch
    for iter_i, (input_nodes, output_nodes, blocks) in enumerate(loader):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 53, in fetch
    data = self.dataset[possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/dataset.py", line 69, in __getitem__
    create_homogeneous_sampled_graphs_from_dataframe_csc(df)
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 556, in create_homogeneous_sampled_graphs_from_dataframe_csc
    *(_process_sampled_df_csc(sampled_df))
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 446, in _process_sampled_df_csc
    major_offsets = cast_to_tensor(df.major_offsets.dropna())
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 229, in __getattr__
    raise AttributeError(
AttributeError: DataFrame object has no attribute major_offsets
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 227, in __getattr__
    return self[key]
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1314, in __getitem__
    return self._get_columns_by_label(arg, downcast=True)
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1973, in _get_columns_by_label
    ca = self._data.select_by_label(labels)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 397, in select_by_label
    return self._select_by_label_grouped(key)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 552, in _select_by_label_grouped
    result = self._grouped_data[key]
KeyError: 'major_offsets'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scripts/bench_cugraph_training.py", line 271, in <module>
    main(args)
  File "/scripts/bench_cugraph_training.py", line 262, in main
    stats = trainer.train()
  File "/scripts/trainers/dgl/trainers_dgl.py", line 211, in train
    num_batches, total_loss = train_epoch(
  File "/scripts/trainers/dgl/trainers_dgl.py", line 90, in train_epoch
    for iter_i, (input_nodes, output_nodes, blocks) in enumerate(loader):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 53, in fetch
    data = self.dataset[possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/dataset.py", line 69, in __getitem__
    create_homogeneous_sampled_graphs_from_dataframe_csc(df)
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 556, in create_homogeneous_sampled_graphs_from_dataframe_csc
    *(_process_sampled_df_csc(sampled_df))
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 446, in _process_sampled_df_csc
    major_offsets = cast_to_tensor(df.major_offsets.dropna())
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 229, in __getattr__
    raise AttributeError(
AttributeError: DataFrame object has no attribute major_offsets
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 227, in __getattr__
    return self[key]
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1314, in __getitem__
    return self._get_columns_by_label(arg, downcast=True)
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1973, in _get_columns_by_label
    ca = self._data.select_by_label(labels)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 397, in select_by_label
    return self._select_by_label_grouped(key)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 552, in _select_by_label_grouped
    result = self._grouped_data[key]
KeyError: 'major_offsets'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scripts/bench_cugraph_training.py", line 271, in <module>
    main(args)
  File "/scripts/bench_cugraph_training.py", line 262, in main
    stats = trainer.train()
  File "/scripts/trainers/dgl/trainers_dgl.py", line 211, in train
    num_batches, total_loss = train_epoch(
  File "/scripts/trainers/dgl/trainers_dgl.py", line 90, in train_epoch
    for iter_i, (input_nodes, output_nodes, blocks) in enumerate(loader):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 53, in fetch
    data = self.dataset[possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/dataset.py", line 69, in __getitem__
    create_homogeneous_sampled_graphs_from_dataframe_csc(df)
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 556, in create_homogeneous_sampled_graphs_from_dataframe_csc
    *(_process_sampled_df_csc(sampled_df))
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 446, in _process_sampled_df_csc
    major_offsets = cast_to_tensor(df.major_offsets.dropna())
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 229, in __getattr__
    raise AttributeError(
AttributeError: DataFrame object has no attribute major_offsets
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 227, in __getattr__
    return self[key]
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1314, in __getitem__
    return self._get_columns_by_label(arg, downcast=True)
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1973, in _get_columns_by_label
    ca = self._data.select_by_label(labels)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 397, in select_by_label
    return self._select_by_label_grouped(key)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 552, in _select_by_label_grouped
    result = self._grouped_data[key]
KeyError: 'major_offsets'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scripts/bench_cugraph_training.py", line 271, in <module>
    main(args)
  File "/scripts/bench_cugraph_training.py", line 262, in main
    stats = trainer.train()
  File "/scripts/trainers/dgl/trainers_dgl.py", line 211, in train
    num_batches, total_loss = train_epoch(
  File "/scripts/trainers/dgl/trainers_dgl.py", line 90, in train_epoch
    for iter_i, (input_nodes, output_nodes, blocks) in enumerate(loader):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 53, in fetch
    data = self.dataset[possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/dataset.py", line 69, in __getitem__
    create_homogeneous_sampled_graphs_from_dataframe_csc(df)
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 556, in create_homogeneous_sampled_graphs_from_dataframe_csc
    *(_process_sampled_df_csc(sampled_df))
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 446, in _process_sampled_df_csc
    major_offsets = cast_to_tensor(df.major_offsets.dropna())
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 229, in __getattr__
    raise AttributeError(
AttributeError: DataFrame object has no attribute major_offsets
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 227, in __getattr__
    return self[key]
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1314, in __getitem__
    return self._get_columns_by_label(arg, downcast=True)
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1973, in _get_columns_by_label
    ca = self._data.select_by_label(labels)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 397, in select_by_label
    return self._select_by_label_grouped(key)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 552, in _select_by_label_grouped
    result = self._grouped_data[key]
KeyError: 'major_offsets'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scripts/bench_cugraph_training.py", line 271, in <module>
    main(args)
  File "/scripts/bench_cugraph_training.py", line 262, in main
    stats = trainer.train()
  File "/scripts/trainers/dgl/trainers_dgl.py", line 211, in train
    num_batches, total_loss = train_epoch(
  File "/scripts/trainers/dgl/trainers_dgl.py", line 90, in train_epoch
    for iter_i, (input_nodes, output_nodes, blocks) in enumerate(loader):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 53, in fetch
    data = self.dataset[possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/dataset.py", line 69, in __getitem__
    create_homogeneous_sampled_graphs_from_dataframe_csc(df)
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 556, in create_homogeneous_sampled_graphs_from_dataframe_csc
    *(_process_sampled_df_csc(sampled_df))
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 446, in _process_sampled_df_csc
    major_offsets = cast_to_tensor(df.major_offsets.dropna())
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 229, in __getattr__
    raise AttributeError(
AttributeError: DataFrame object has no attribute major_offsets
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 227, in __getattr__
    return self[key]
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1314, in __getitem__
    return self._get_columns_by_label(arg, downcast=True)
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1973, in _get_columns_by_label
    ca = self._data.select_by_label(labels)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 397, in select_by_label
    return self._select_by_label_grouped(key)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 552, in _select_by_label_grouped
    result = self._grouped_data[key]
KeyError: 'major_offsets'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scripts/bench_cugraph_training.py", line 271, in <module>
    main(args)
  File "/scripts/bench_cugraph_training.py", line 262, in main
    stats = trainer.train()
  File "/scripts/trainers/dgl/trainers_dgl.py", line 211, in train
    num_batches, total_loss = train_epoch(
  File "/scripts/trainers/dgl/trainers_dgl.py", line 90, in train_epoch
    for iter_i, (input_nodes, output_nodes, blocks) in enumerate(loader):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 53, in fetch
    data = self.dataset[possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/dataset.py", line 69, in __getitem__
    create_homogeneous_sampled_graphs_from_dataframe_csc(df)
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 556, in create_homogeneous_sampled_graphs_from_dataframe_csc
    *(_process_sampled_df_csc(sampled_df))
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 446, in _process_sampled_df_csc
    major_offsets = cast_to_tensor(df.major_offsets.dropna())
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 229, in __getattr__
    raise AttributeError(
AttributeError: DataFrame object has no attribute major_offsets
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 227, in __getattr__
    return self[key]
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1314, in __getitem__
    return self._get_columns_by_label(arg, downcast=True)
  File "/opt/conda/lib/python3.10/site-packages/nvtx/nvtx.py", line 115, in inner
    result = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py", line 1973, in _get_columns_by_label
    ca = self._data.select_by_label(labels)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 397, in select_by_label
    return self._select_by_label_grouped(key)
  File "/opt/conda/lib/python3.10/site-packages/cudf/core/column_accessor.py", line 552, in _select_by_label_grouped
    result = self._grouped_data[key]
KeyError: 'major_offsets'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scripts/bench_cugraph_training.py", line 271, in <module>
    main(args)
  File "/scripts/bench_cugraph_training.py", line 262, in main
    stats = trainer.train()
  File "/scripts/trainers/dgl/trainers_dgl.py", line 211, in train
    num_batches, total_loss = train_epoch(
  File "/scripts/trainers/dgl/trainers_dgl.py", line 90, in train_epoch
    for iter_i, (input_nodes, output_nodes, blocks) in enumerate(loader):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 53, in fetch
    data = self.dataset[possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/dataset.py", line 69, in __getitem__
    create_homogeneous_sampled_graphs_from_dataframe_csc(df)
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 556, in create_homogeneous_sampled_graphs_from_dataframe_csc
    *(_process_sampled_df_csc(sampled_df))
  File "/opt/conda/lib/python3.10/site-packages/cugraph_dgl/dataloading/utils/sampling_helpers.py", line 446, in _process_sampled_df_csc
    major_offsets = cast_to_tensor(df.major_offsets.dropna())
  File "/opt/conda/lib/python3.10/site-packages/cudf/utils/utils.py", line 229, in __getattr__
    raise AttributeError(
AttributeError: DataFrame object has no attribute major_offsets
[2024-01-19 16:14:53,045] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1600919 closing signal SIGTERM
[2024-01-19 16:14:53,045] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1600920 closing signal SIGTERM
[2024-01-19 16:14:53,045] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1600921 closing signal SIGTERM
[2024-01-19 16:14:53,046] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1600922 closing signal SIGTERM
[2024-01-19 16:14:53,048] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1600923 closing signal SIGTERM
[2024-01-19 16:14:53,048] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1600924 closing signal SIGTERM
[2024-01-19 16:14:53,803] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 6 (pid: 1600925) of binary: /opt/conda/bin/python
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.2', 'console_scripts', 'torchrun')())
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/scripts/bench_cugraph_training.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-01-19_16:14:53
  host      : luna-0069.selene.nvidia.com
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 1600926)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-01-19_16:14:53
  host      : luna-0069.selene.nvidia.com
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 1600925)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: luna-0069: task 0: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=4635074.2
